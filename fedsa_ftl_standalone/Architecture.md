1. LoRA (Low-Rank Adaptation)
	•	大きなモデルの重み W を凍結し、低ランク行列 A, B を追加して学習する仕組み。
	•	形式：W’ = W + B \cdot A
	•	メリット：学習パラメータ数が少なく、通信や更新が効率的になる。

⸻

2. DP-LoRA (Differentially Private LoRA)
	•	差分プライバシー(DP) を LoRA に適用した手法。
	•	各クライアントが A と B の両方を学習してサーバに送信。
	•	サーバ集約前に、クライアント側で
	1.	勾配を L2 ノルムでクリップ
	2.	その後 ガウスノイズを付与
	•	これにより、送信される更新が差分プライベートになり、個別データが推測されにくくなる。
	•	サーバは サンプル数に基づいた加重平均 で更新を集約する。

⸻

3. FedSA-LoRA (Federated Split Adaptation with LoRA)
	•	Federated Learning の変種。LoRA の分解を活かして通信効率と個人化を両立。
	•	A 行列（汎化情報）だけをサーバに送信・共有。
	•	B 行列（個人依存情報）はローカル保持し、送らない。
	•	サーバは受け取った A を集約して配布する。
	•	各クライアントは W' = W + B_i \cdot A_global を使い続ける。
→ 「A = グローバル知識」「B = ローカル特徴」と役割を分けている。

⸻

4. 今回やりたいこと（DP-FedSA-LoRA）
	•	FedSA-LoRA の仕組みをベースにする。
	•	A だけ送信・共有
	•	B はローカル保持
	•	さらに DP-LoRA の考え方を A にだけ適用する。
	•	A の勾配をクリップ＋ノイズ付与してから送信
	•	サーバは 加重平均で A を集約し、再配布する。

# Configuration for ResNet101 on CIFAR-100 with FedSA-FTL
# Deeper model for potentially better accuracy

# Random seed for reproducibility
seed: 42

# Device configuration
use_gpu: true

# Data configuration
data:
  dataset_name: cifar100
  data_dir: ./data
  num_clients: 10
  data_split: non_iid  # 'iid' or 'non_iid'
  alpha: 0.3  # Lower alpha for more heterogeneous data
  batch_size: 32  # Smaller batch size for deeper model
  num_workers: 4
  model_type: resnet
  verbose: false
  
  # Data augmentation settings - stronger augmentation for deeper model
  augmentations:
    horizontal_flip:
      enabled: true
      prob: 0.5
    
    random_rotation:
      enabled: true
      degrees: 10
    
    color_jitter:
      enabled: true
      brightness: 0.3
      contrast: 0.3
      saturation: 0.3
      hue: 0.15
    
    random_crop:
      enabled: true
      padding: 4
    
    random_erasing:
      enabled: true  # Enable for ResNet101
      prob: 0.3
      scale: [0.02, 0.33]
      ratio: [0.3, 3.3]
    
    # Advanced augmentations for deeper model
    mixup:
      enabled: true
      alpha: 0.4
      prob: 0.3
    
    cutmix:
      enabled: true
      alpha: 1.0
      prob: 0.3

# Model configuration
model:
  model_name: resnet101  # Deeper ResNet variant
  num_classes: 100
  pretrained: true
  
  # LoRA configuration (smaller rank for deeper model)
  lora_r: 4  # Smaller rank to reduce parameters
  lora_alpha: 8
  lora_dropout: 0.15  # Slightly higher dropout

# Training configuration
training:
  epochs: 3  # Fewer local epochs for deeper model
  lr: 0.0005  # Lower learning rate for stability
  momentum: 0.9
  weight_decay: 0.0001
  scheduler: cosine
  warmup_epochs: 1
  optimizer: adamw  # Use AdamW for deeper model
  gradient_clip: 0.5  # More aggressive clipping

# Federated learning configuration
federated:
  num_rounds: 80  # Fewer rounds needed for deeper model
  num_clients: 10
  client_fraction: 0.8  # Sample 80% of clients each round
  aggregation_method: fedavg
  checkpoint_freq: 15

# Privacy configuration
privacy:
  enable_privacy: false
  epsilon: 10.0
  delta: 1e-5
  max_grad_norm: 0.3  # Tighter gradient clipping

# Evaluation configuration
evaluation:
  eval_freq: 3  # More frequent evaluation
  save_best_model: true
  metric: accuracy
  patience: 15

# Experiment configuration
experiment:
  name: ResNet101_CIFAR100_NonIID
  output_dir: experiments/quickstart_resnet
  save_model: true
  save_history: true
  log_interval: 5
  
  use_wandb: false
  wandb_project: fedsa-ftl-resnet
  wandb_entity: null

# Reproducibility settings
reproducibility:
  deterministic: false

# Communication efficiency settings
communication:
  compress: true  # Enable compression for larger model
  compression_ratio: 0.05  # More aggressive compression
  quantization_bits: 8  # 8-bit quantization

# Advanced settings
advanced:
  use_fbftl: false
  feature_extraction_rounds: 10
  personalized: true
  personalization_layers: ['classifier', 'lora_B']
  server_lr: 0.005
  server_momentum: 0.95
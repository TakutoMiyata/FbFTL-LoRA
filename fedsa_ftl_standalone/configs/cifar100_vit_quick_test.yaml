# Quick test configuration for debugging and initial experiments
# Reduced settings for faster iteration

seed: 42
use_gpu: true

experiment:
  name: "fedsa_ftl_cifar100_vit_quick_test"
  description: "Quick test configuration for debugging"
  output_dir: "experiments/quick_test"

model:
  num_classes: 100
  model_name: "vit_tiny"  # Smallest model for quick testing
  lora_r: 8  # Small rank for quick testing
  lora_alpha: 16
  lora_dropout: 0.1
  freeze_backbone: true
  pretrained: false

data:
  dataset_name: "cifar100"
  data_dir: "./data"
  batch_size: 64  # Larger batch for faster training
  num_workers: 2
  data_split: "non_iid"
  alpha: 0.5
  model_type: "vit"
  verbose: false  # Reduce output

federated:
  num_clients: 5  # Fewer clients for quick testing
  num_rounds: 20  # Fewer rounds
  client_fraction: 0.4  # Sample 2 clients per round
  checkpoint_freq: 5
  save_best_model: true
  aggregation_method: "fedavg"

training:
  local_epochs: 1  # Minimal local training
  optimizer: "adamw"
  learning_rate: 0.0005
  weight_decay: 0.001
  betas: [0.9, 0.999]
  eps: 1e-8
  grad_clip: 1.0
  accumulation_steps: 1

privacy:
  enable_privacy: false

logging:
  log_level: "INFO"
  save_logs: true
  tensorboard: false
  wandb: false

evaluation:
  eval_freq: 1  # Evaluate every round for debugging
  eval_on_train: false
  eval_on_test: true
  save_predictions: false

reproducibility:
  deterministic: false
  benchmark: true